{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf44844-d2c0-4141-86d5-cb641654c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Ridge, ElasticNet, SGDRegressor, LinearRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import RANSACRegressor, TheilSenRegressor\n",
    "\n",
    "# Load the data\n",
    "file_path = \"../Data_ML/4_out_csvs_regression/output_bfill_imputed.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define columns\n",
    "data_columns = [\n",
    "    'OF2', 'OF3', 'OF4', 'OF5', 'OF6', 'OF7', 'OF8', 'OF9', 'OF10', 'OF11', 'OF13', 'OF14', 'OF15', 'OF16', 'OF17',\n",
    "    'OF18', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24', 'OF25', 'OF26', 'OF27', 'OF28', 'OF30', 'OF31',\n",
    "    'OF33', 'OF34', 'OF37', 'OF38', 'F1', 'F2', 'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F4', 'F5', 'F6',\n",
    "    'F7', 'F8', 'F9', 'F10', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23',\n",
    "    'F24', 'F25', 'F28', 'F29', 'F30', 'F31', 'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40',\n",
    "    'F41', 'F43', 'F44', 'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F56', 'F57',\n",
    "    'F58', 'F59', 'F62', 'F63', 'F64', 'F65', 'F67', 'F68', 'S1', 'S2', 'S4', 'S5','Provincial_Class','Federal_Class','Regime','Vegetation_Type','Vegetation_Cover','Woody_Canopy_Cover','Moss_Cover','Phragmites','Soil_Type','Surface_Water_Present','Saturation_Depth','Living_Moss_Depth','Organic_Depth','Hydrogeomorphic_Class'\n",
    "]\n",
    "#results_columns = ['PR_Benefit', 'NR_Benefit', 'SR_Benefit', 'WS_Benefit', 'SFST_Benefit', 'PR_Benefit', 'NR_Benefit', 'SR', 'WS_Benefit', 'SFST_Benefit']\n",
    "results_columns = ['PR','NR','WS','SFST']\n",
    "\n",
    "\n",
    "for result in results_columns:\n",
    "    print(result)\n",
    "    #print(result)\n",
    "    X = data[data_columns]\n",
    "    y = data[result]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models\n",
    "    models = [\n",
    "        Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(), \n",
    "        KNeighborsRegressor(), MLPRegressor(max_iter=200), ElasticNet(max_iter=1000), \n",
    "        SVR(cache_size=1000), BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(), \n",
    "        TheilSenRegressor()\n",
    "    ]\n",
    "\n",
    "    # Create dictionaries to store feature importances for all models\n",
    "    all_feature_importances_avg = {col: [] for col in X.columns}\n",
    "    points_per_feature = {col: 0 for col in X.columns}\n",
    "    top_bottom_features_per_model = {type(model).__name__: {'Top 2': [], 'Bottom 2': []} for model in models}\n",
    "\n",
    "    # Iterate over models\n",
    "    for model in models:\n",
    "        #print(str(model))\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Perform permutation feature importance analysis\n",
    "        perm_importance = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "        # Get feature importances\n",
    "        feature_importances = perm_importance.importances_mean\n",
    "\n",
    "        # Get indices of features sorted by importance\n",
    "        most_important_indices = feature_importances.argsort()[-2:][::-1]\n",
    "        least_important_indices = feature_importances.argsort()[:2]\n",
    "        \n",
    "        important_indices = feature_importances.argsort()[:]\n",
    "\n",
    "        # Calculate points for each feature\n",
    "        for i in range(len(important_indices)):\n",
    "            points_per_feature[X.columns[important_indices[i]]] += i\n",
    "\n",
    "        # Store top 2 and bottom 2 important features\n",
    "        for idx in most_important_indices:\n",
    "            top_bottom_features_per_model[type(model).__name__]['Top 2'].append((X.columns[idx], feature_importances[idx]))\n",
    "        for idx in least_important_indices:\n",
    "            top_bottom_features_per_model[type(model).__name__]['Bottom 2'].append((X.columns[idx], feature_importances[idx]))\n",
    "\n",
    "        # Append the feature importances to the dictionary\n",
    "        for idx, col in enumerate(X.columns):\n",
    "            all_feature_importances_avg[col].append(feature_importances[idx])\n",
    "\n",
    "    # Calculate average feature importance across all models\n",
    "    for col, importances in all_feature_importances_avg.items():\n",
    "        if len(importances) > 0:\n",
    "            all_feature_importances_avg[col] = np.mean(importances)\n",
    "\n",
    "    # Get indices of features sorted by average importance\n",
    "    sorted_indices_avg = np.argsort(list(all_feature_importances_avg.values()))[::-1]\n",
    "\n",
    "    # Sort features based on points\n",
    "    sorted_features = sorted(points_per_feature.keys(), key=lambda x: points_per_feature[x], reverse=True)\n",
    "    sorted_average_importances = [all_feature_importances_avg[feature] for feature in sorted_features]\n",
    "    sorted_points = [points_per_feature[feature] for feature in sorted_features]\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax1 = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Features')\n",
    "    plt.xticks(rotation=90, ha='center')\n",
    "    ax1.set_ylabel('Average Importance (Log Scale)', color=color)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.bar(sorted_features, sorted_average_importances, color=color, alpha=0.6)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Points', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(sorted_features, sorted_points, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.xticks(rotation=90, ha='center')\n",
    "    plt.title(f'Feature Importance and Points per Feature for {result}')\n",
    "    plt.savefig(f'feature_importance_points_plot_{result}.png')\n",
    "\n",
    "    # Generate LaTeX table\n",
    "    latex_code = r\"\"\"\n",
    "\n",
    "\n",
    "\\begin{table}[h!]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Model} & \\textbf{Top 2 Important Features} & \\textbf{Bottom 2 Important Features} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "    for model, features in top_bottom_features_per_model.items():\n",
    "        latex_code += f\"{model} & \\n\"\n",
    "        latex_code += \"\\\\begin{tabular}[c]{@{}l@{}}\\n\"\n",
    "        for feature, importance in features['Top 2']:\n",
    "            latex_code += f\"'{feature}': {importance:.6f}\\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\end{tabular} & \\n\"\n",
    "        latex_code += \"\\\\begin{tabular}[c]{@{}l@{}}\\n\"\n",
    "        for feature, importance in features['Bottom 2']:\n",
    "            latex_code += f\"'{feature}': {importance:.6f}\\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\end{tabular} \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\hline\\n\"\n",
    "\n",
    "    # Average importance\n",
    "    latex_code += r\"\\textbf{Average Importance} & \\begin{tabular}[c]{@{}l@{}}\"\n",
    "    for idx in sorted_indices_avg[:4]:\n",
    "        latex_code += f\"'Feature {list(all_feature_importances_avg.keys())[idx]}': {list(all_feature_importances_avg.values())[idx]:.6f}\\\\\\\\\\n\"\n",
    "    latex_code += r\"\\end{tabular} & \\begin{tabular}[c]{@{}l@{}}\"\n",
    "    for idx in sorted_indices_avg[-4:]:\n",
    "        latex_code += f\"'Feature {list(all_feature_importances_avg.keys())[idx]}': {list(all_feature_importances_avg.values())[idx]:.6f}\\\\\\\\\\n\"\n",
    "    latex_code += r\"\\end{tabular} \\\\ \\hline\"\n",
    "\n",
    "    # Voting system\n",
    "    sorted_points_features = sorted(points_per_feature.keys(), key=lambda x: points_per_feature[x], reverse=True)\n",
    "    latex_code += r\"\\textbf{Voting System} & \\begin{tabular}[c]{@{}l@{}}\"\n",
    "    for feature in sorted_points_features[:4]:\n",
    "        latex_code += f\"'Feature {feature}': {points_per_feature[feature]} points\\\\\\\\\\n\"\n",
    "    latex_code += r\"\\end{tabular} & \\begin{tabular}[c]{@{}l@{}}\"\n",
    "    for feature in sorted_points_features[-4:]:\n",
    "        latex_code += f\"'Feature {feature}': {points_per_feature[feature]} points\\\\\\\\\\n\"\n",
    "    latex_code += r\"\\end{tabular} \\\\ \\hline\"\n",
    "\n",
    "    latex_code += r\"\"\"\n",
    "\\end{tabular}\n",
    "\\caption{Features for \"\"\" + result + r\"\"\" Models}\n",
    "\\label{tab:important_features_\"\"\" + result + r\"\"\"}\n",
    "\\end{table}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Save LaTeX code to file\n",
    "    with open(f'feature_importance_table_{result}.tex', 'w') as f:\n",
    "        f.write(latex_code)\n",
    "    \n",
    "    # Print LaTeX code\n",
    "    print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89baf8-b38d-4583-8ffd-9d11d5c3be8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
