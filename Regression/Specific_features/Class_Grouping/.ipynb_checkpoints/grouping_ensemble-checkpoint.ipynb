{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f76de3-5ccf-45b7-9e93-b9e18aa8d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration for all functions\n",
    "config = {\n",
    "    \"WS\": {\"min\": 1.58, \"max\": 8.61, \"lower\": 3.07, \"higher\": 6.17},\n",
    "    \"PR\": {\"min\": 2.07, \"max\": 10.0, \"lower\": 3.66, \"higher\": 6.11},\n",
    "    \"NR\": {\"min\": 4.10, \"max\": 10.0, \"lower\": 2.06, \"higher\": 4.42},\n",
    "    \"SR\": {\"min\": 2.29, \"max\": 10.0, \"lower\": 3.02, \"higher\": 6.67},\n",
    "    \"SFST\": {\"min\": 0.0, \"max\": 7.71, \"lower\": 1.05, \"higher\": 6.51},\n",
    "    \"WS_Benefit\": {\"min\": 0.08, \"max\": 10.0, \"lower\": 2.65, \"higher\": 6.50},\n",
    "    \"PR_Benefit\": {\"min\": 0.49, \"max\": 10.0, \"lower\": 3.29, \"higher\": 6.68},\n",
    "    \"NR_Benefit\": {\"min\": 0.71, \"max\": 10.0, \"lower\": 4.10, \"higher\": 7.76},\n",
    "    \"SR_Benefit\": {\"min\": 0.49, \"max\": 8.79, \"lower\": 2.94, \"higher\": 6.19},\n",
    "    \"SFST_Benefit\": {\"min\": 0.0, \"max\": 7.19, \"lower\": 1.86, \"higher\": 5.30}\n",
    "}\n",
    "\n",
    "# Define the data columns\n",
    "data_columns = [ 'Provincial_Class','Federal_Class','Regime','Vegetation_Type','Vegetation_Cover','Woody_Canopy_Cover','Moss_Cover','Phragmites','Soil_Type',\n",
    "'Surface_Water_Present','Saturation_Depth','Living_Moss_Depth','Organic_Depth','Hydrogeomorphic_Class',\n",
    "    'OF2', 'OF3', 'OF4', 'OF5', 'OF6', 'OF7', 'OF8', 'OF9', 'OF10', 'OF11', 'OF13', 'OF14', 'OF15', 'OF16', 'OF17',\n",
    "    'OF18', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24', 'OF25', 'OF26', 'OF27', 'OF28',  'OF30', 'OF31',\n",
    "    'OF33', 'OF34', 'OF37', 'OF38', 'F1', 'F2', 'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F4', 'F5', 'F6',\n",
    "    'F7', 'F8', 'F9', 'F10', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23',\n",
    "    'F24', 'F25',  'F28', 'F29', 'F30', 'F31', 'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40',\n",
    "    'F41',  'F43', 'F44', 'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F56', 'F57',\n",
    "    'F58', 'F59', 'F62', 'F63', 'F64', 'F65', 'F67', 'F68', 'S1', 'S2', 'S4', 'S5'\n",
    "]\n",
    "\n",
    "# Function to load, evaluate, and retrain the model\n",
    "def load_and_train_model(model_file, model_name, hyperparameters, column, base_dir):\n",
    "    # Load the model\n",
    "    model = joblib.load(model_file)\n",
    "    \n",
    "    # Extract the base CSV file name\n",
    "    base_csv_name = '_'.join(os.path.basename(model_file).split('_')[:-2]) \n",
    "\n",
    "    # Load the data for this model\n",
    "    csv_file = os.path.join('../../../Data_ML/4_out_csvs_regression', base_csv_name)\n",
    "    data = pd.read_csv(csv_file)\n",
    "    X = data[data_columns]\n",
    "    y = data[column]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Retrain the model if it is a specific type\n",
    "    if model_name == 'GradientBoostingRegressor':\n",
    "        model = GradientBoostingRegressor(loss='squared_error', **hyperparameters)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict using the model\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    return model, X_test_scaled, y_test, y_pred, csv_file\n",
    "\n",
    "def normalize(values, min_val, max_val):\n",
    "    return 10 * ((values - min_val) / (max_val - min_val))\n",
    "\n",
    "def classify(value, lower, higher):\n",
    "    if value < lower:\n",
    "        return \"lower\"\n",
    "    elif value <= higher:\n",
    "        return \"moderate\"\n",
    "    else:\n",
    "        return \"higher\"\n",
    "\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
    "    return correct / len(actual) if actual else 0\n",
    "\n",
    "def voting_classification(predictions):\n",
    "    return [Counter(pred).most_common(1)[0][0] for pred in zip(*predictions)]\n",
    "\n",
    "# Function to evaluate models for a given function\n",
    "def evaluate_models_for_function(function, params, base_dir, normalize_data=True):\n",
    "    model_directory = f\"{base_dir}/{function}\"\n",
    "    results = []\n",
    "    for model_file in os.listdir(model_directory):\n",
    "        if model_file.endswith(\".pkl\"):\n",
    "            model_name = model_file.split('_')[-2]\n",
    "            hyperparameters = {}  # No hyperparameters provided when loading from file\n",
    "            model, X_test_scaled, y_test, y_pred, csv_file = load_and_train_model(os.path.join(model_directory, model_file), model_name, hyperparameters, function, '../../../Data_ML/4_out_csvs_regression')\n",
    "            \n",
    "            if model is not None:\n",
    "                if normalize_data:\n",
    "                    # Normalize and classify the predictions\n",
    "                    y_test_normalized = normalize(y_test, params['min'], params['max'])\n",
    "                    y_pred_normalized = normalize(y_pred, params['min'], params['max'])\n",
    "                    classified_actual = [classify(val, params['lower'], params['higher']) for val in y_test_normalized]\n",
    "                    classified_predicted = [classify(val, params['lower'], params['higher']) for val in y_pred_normalized]\n",
    "                else:\n",
    "                    # Classify the predictions without normalization\n",
    "                    classified_actual = [classify(val, params['lower'], params['higher']) for val in y_test]\n",
    "                    classified_predicted = [classify(val, params['lower'], params['higher']) for val in y_pred]\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                accuracy = calculate_accuracy(classified_actual, classified_predicted)\n",
    "                results.append((csv_file, model_name, accuracy, classified_actual, classified_predicted))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results(function, results, label):\n",
    "    # Sort results based on accuracy\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Print the top result for each function\n",
    "    if results:\n",
    "        top_result = results[0]\n",
    "        csv_file, model_name, accuracy, classified_actual, classified_predicted = top_result\n",
    "        \n",
    "        # Accumulate class-wise accuracy\n",
    "        global_correct = {'lower': 0, 'moderate': 0, 'higher': 0}\n",
    "        global_total = {'lower': 0, 'moderate': 0, 'higher': 0}\n",
    "        for actual, predicted in zip(classified_actual, classified_predicted):\n",
    "            global_total[actual] += 1\n",
    "            if actual == predicted:\n",
    "                global_correct[actual] += 1\n",
    "\n",
    "        # Calculate and print global accuracy\n",
    "        overall_accuracy = sum(global_correct.values()) / sum(global_total.values()) if sum(global_total.values()) > 0 else 0\n",
    "\n",
    "        print(f\"\\n{function} Top Result ({label}):\")\n",
    "        print(f\"CSV File: {os.path.basename(csv_file)}, Model: {model_name}, Accuracy: {accuracy:.2%}\")\n",
    "        print(f\"Global Accuracy: {overall_accuracy:.2%}\")\n",
    "        \n",
    "        for category in ['lower', 'moderate', 'higher']:\n",
    "            category_accuracy = global_correct[category] / global_total[category] if global_total[category] > 0 else 0\n",
    "            print(f\"Accuracy for '{category}': {category_accuracy:.2%}\")\n",
    "\n",
    "        # Ensemble learning and voting\n",
    "        top_5_models = results[:5]\n",
    "        ensemble_predictions = [res[4] for res in top_5_models]\n",
    "        ensemble_actual = top_5_models[0][3]\n",
    "        \n",
    "        ensemble_votes = voting_classification(ensemble_predictions)\n",
    "        ensemble_accuracy = calculate_accuracy(ensemble_actual, ensemble_votes)\n",
    "\n",
    "        # Overall voting accuracy calculation\n",
    "        all_predictions = [res[4] for res in results]\n",
    "        all_actual = results[0][3]\n",
    "        \n",
    "        voting_votes = voting_classification(all_predictions)\n",
    "        voting_accuracy = calculate_accuracy(all_actual, voting_votes)\n",
    "\n",
    "        # Per-category accuracies for ensemble and voting\n",
    "        categories = [\"lower\", \"moderate\", \"higher\"]\n",
    "        ensemble_category_accuracy = {category: 0 for category in categories}\n",
    "        voting_category_accuracy = {category: 0 for category in categories}\n",
    "\n",
    "        for category in categories:\n",
    "            if ensemble_actual.count(category) > 0:\n",
    "                ensemble_category_accuracy[category] = sum(1 for a, p in zip(ensemble_actual, ensemble_votes) if a == p == category) / ensemble_actual.count(category)\n",
    "            else:\n",
    "                ensemble_category_accuracy[category] = 0\n",
    "            \n",
    "            if all_actual.count(category) > 0:\n",
    "                voting_category_accuracy[category] = sum(1 for a, p in zip(all_actual, voting_votes) if a == p == category) / all_actual.count(category)\n",
    "            else:\n",
    "                voting_category_accuracy[category] = 0\n",
    "\n",
    "        # Print ensemble and voting results\n",
    "        print(f\"\\n{function} Ensemble and Voting Results ({label}):\")\n",
    "        print(f\"Overall Ensemble Accuracy: {ensemble_accuracy:.2%}\")\n",
    "        print(f\"Overall Voting Accuracy: {voting_accuracy:.2%}\")\n",
    "        for category in categories:\n",
    "            print(f\"Ensemble Accuracy for '{category}': {ensemble_category_accuracy[category]:.2%}\")\n",
    "            print(f\"Voting Accuracy for '{category}': {voting_category_accuracy[category]:.2%}\")\n",
    "\n",
    "# Evaluate models for each function in the config\n",
    "for function, params in config.items():\n",
    "    #print(f\"\\nEvaluating Non-Normalized Models for {function}...\")\n",
    "    #results_non_norm = evaluate_models_for_function(function, params, \"../TrainingResults/non_norm\", normalize_data=False)\n",
    "    #print_results(function, results_non_norm, \"Non-Normalized\")\n",
    "\n",
    "    print(f\"\\nEvaluating Pre-Normalized Models for {function}...\")\n",
    "    results_norm = evaluate_models_for_function(function, params, \"../TrainingResults/norm\", normalize_data=False)\n",
    "    print_results(function, results_norm, \"Pre-Normalized\")\n",
    "\n",
    "    print(f\"\\nEvaluating Normalized Models (from Non-Norm Data) for {function}...\")\n",
    "    results_non_norm_normalized = evaluate_models_for_function(function, params, \"../TrainingResults/non_norm\", normalize_data=True)\n",
    "    print_results(function, results_non_norm_normalized, \"Normalized from Non-Normalized Data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
