{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee3818d-c256-4f30-af47-d018f0bd0d2f",
   "metadata": {},
   "source": [
    "# PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca00f5d-49d9-4153-b704-52eddb9fb2ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../../Data_ML/4_out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 0.5241212658706805\n",
      "Processing DecisionTreeRegressor() for ../../../Data_ML/4_out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 0.6363413529390632\n",
      "Processing GradientBoostingRegressor() for ../../../Data_ML/4_out_csvs_regression\\output_bfill_imputed.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 244\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Process each CSV file\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[1;32m--> 244\u001b[0m     best_model_info \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     best_models_info\u001b[38;5;241m.\u001b[39mappend(best_model_info)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Save the best model information for each CSV file to a CSV file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 201\u001b[0m, in \u001b[0;36mprocess_csv\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[0;32m    200\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid[model_name], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     best_estimator \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    203\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:221\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mis_multi_class:\n\u001b[0;32m    219\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(original_y \u001b[38;5;241m==\u001b[39m k, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m--> 221\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_predictions_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# induce regression tree on residuals\u001b[39;00m\n\u001b[0;32m    226\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(\n\u001b[0;32m    227\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion,\n\u001b[0;32m    228\u001b[0m     splitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m     ccp_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mccp_alpha,\n\u001b[0;32m    238\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py:461\u001b[0m, in \u001b[0;36mHuberLossFunction.negative_gradient\u001b[1;34m(self, y, raw_predictions, sample_weight, **kargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(np\u001b[38;5;241m.\u001b[39mabs(diff), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m \u001b[43m_weighted_percentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m gamma_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(diff) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m gamma\n\u001b[0;32m    463\u001b[0m residual \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\utils\\stats.py:40\u001b[0m, in \u001b[0;36m_weighted_percentile\u001b[1;34m(array, sample_weight, percentile)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     39\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(sample_weight, (array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 40\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m sorted_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake_along_axis(sample_weight, sorted_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Find index of median prediction for each sample\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\greystone\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "    'OF22', 'OF26', 'OF27', 'F17', 'F20', 'F21', 'F23',\n",
    "    'F24',  'F28', 'F29', 'F31', 'F33', 'F34', 'F35', 'F36', 'F38', 'F43', 'F44', 'F45', 'F49', 'F63', 'F65', \n",
    "]\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"PR\"\n",
    "results_columns = [model_directory]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c252c-1a40-470f-a1b2-74387c7c5d54",
   "metadata": {},
   "source": [
    "# SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e96f4a-dcde-4244-a2f0-1180ab67df4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = ['OF22', 'OF26', 'OF27', 'F9',  'F17',  'F20', 'F22',  'F28', 'F29', 'F31', 'F33', 'F34', 'F35', 'F36',  'F43', 'F44', 'F45',  'F49',  'S5']\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"SR\"\n",
    "results_columns = [model_directory]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb86154-37ee-42df-ba1e-37285272c016",
   "metadata": {},
   "source": [
    "# NR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b70b1-31d4-48f1-8cd9-8c020ee15bb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "    'OF16','OF18', 'OF22', 'OF25', 'OF26', 'OF27', 'F1',  'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F6',\n",
    "    'F17', 'F18',  'F20', 'F21', 'F22', 'F23',\n",
    "    'F24',  'F28', 'F31',  'F33', 'F34', 'F36', 'F43', 'F44', 'F45', 'F48', 'F49',  'F54', 'F65', 'S5'\n",
    "]\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"NR\"\n",
    "results_columns = [model_directory]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310babf8-489f-4461-b9bd-3848dcc72408",
   "metadata": {},
   "source": [
    "# WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39415519-eea5-4a3b-8e73-b41eb5000be3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = ['OF22', 'OF26', 'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F20', 'F21', 'F22', 'F28', 'F31',  'F43', 'F44', 'F45', 'F48', 'F49']\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"WS\"\n",
    "results_columns = [model_directory]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb769d2-366b-4ba1-8b4a-ea8ef6f025a6",
   "metadata": {},
   "source": [
    "# SFST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7040bb-9f3b-4e14-a896-0fbfede633b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "    'F1', 'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F14', 'F17', 'F21',\n",
    "    'F24', 'F25',  'F29', 'F31',  'F33', 'F34',  'F43', 'F47', 'F48'\n",
    "]\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"SFST\"\n",
    "results_columns = [model_directory]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b999c-4aae-46cd-8af2-c3c6a4cc791d",
   "metadata": {},
   "source": [
    "# WS Benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b27adc-a99f-40d7-940b-4487802b2f6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.8848853842797528\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 0.6715891867163182\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'poisson', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.1262947681499302\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.01, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.3541162961223754\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 10.201073884747036\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 9.744706275721713\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.7055092233168994\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 1}\n",
      "RANSACRegressor RMSE: 3.0151017943872445\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 4.660186535866086\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.2621494722183244\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.8999574897948137\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.500418100460827\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 0.8270964691675755\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.1, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.4006000411655493\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 1.6291856178409578\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': True, 'elasticnet__selection': 'cyclic', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.341247599696954\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.6632070720470944\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.8041664018836654\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 10}\n",
      "TheilSenRegressor RMSE: 2.750893467841145\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.057158305222768\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.8774241105756202\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 1, 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.3328404360523394\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'poisson', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.0154369131026812\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.001, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.4103951194032125\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.2234575626755415\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.34191053272335\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.8158476271018054\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.6255090281803417\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 3.5506317782132277\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.0290451925674144\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.8791450929430225\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 2.1531910068325946\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.826614835553551\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.0765812051992496\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 2.8313389719043256\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 9.585577231035439\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.6423733830179046\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': None}\n",
      "RANSACRegressor RMSE: 2.938463736418994\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 8.26907361197405\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.105431225075473\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.874135523693133\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 0.8799435858540673\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 0.9945080960024011\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.103070305111493\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 3.5192950745967133\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 9.58044075416099\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'invscaling', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.613546881712168\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.6164763601592296\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 2.966898712455822\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B9E5477C40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B9E5477C40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.271535947106056\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.8678069431886781\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.0604813597068616\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 1, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.0874847133617247\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.1, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.344263093793\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.373011563160119\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.34113698687447\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.655062660554102\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 10}\n",
      "RANSACRegressor RMSE: 2.855014330940082\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': 10}\n",
      "TheilSenRegressor RMSE: 3.977474438950314\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B9E54A27A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B9E54A27A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.1587577946735625\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'cholesky'}\n",
      "Ridge RMSE: 1.87606467296504\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.971390088478782\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.630887076543539\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.3720596402788914\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 7.976771550447716\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': True, 'elasticnet__selection': 'cyclic', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.341247599696954\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.648669468802015\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.7203988185445374\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': 10}\n",
      "TheilSenRegressor RMSE: 8.888448411529483\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.174785017052277\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9005464791839861\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.5397200387145216\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.020922305622649\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.3569170616196602\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.2856836891411767\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': True, 'elasticnet__selection': 'cyclic', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.341247599696954\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.6050348043903453\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 5}\n",
      "RANSACRegressor RMSE: 2.7331013135240023\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 13.17995969469741\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.2688944611943596\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.887360512732951\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 0.9238432342278484\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'quantile', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 4.083722805842152\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.2222923055816013\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.01, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.3534414005792605\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'nan_euclidean', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.6395245563971454\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.2417673560456666\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': True, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 9.424351351124931\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 2.7145658013815868\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.8646816588989332\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.8646780950240196\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.8646704983175368\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.2287683650991523\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 10}\n",
      "TheilSenRegressor RMSE: 2.5798954994799\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.2640221102734284\n",
      "Best models information saved to best_models_info.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = ['OF8', 'OF17', 'OF18', 'OF23', 'OF24','F51' ]\n",
    "\n",
    "results_columns = ['WS_Benefit']\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"WS_Benefit\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7bb11-26ff-45af-9415-b6f58f84fd66",
   "metadata": {},
   "source": [
    "# NR Benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce41144a-b0ee-4c84-a309-9321b69b65d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9764256972076324\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.5951951730780909\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.675527622066697\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 1.1124319296412393\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 0.8252713214124646\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.478110495343411\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.5376718956717446\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.7966559090210397\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.365008500932773\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.9683301742130779\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9559734750908635\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.9851588456011235\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.237582400499455\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.7624376084813747\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.3388222876635398\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 2.325168317076102\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.7415362667634517\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.675527622066697\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.2811580650407857\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 20}\n",
      "AdaBoostRegressor RMSE: 0.9124656814240304\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.5145507819983037\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.4610898627912537\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.8316059781239835\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.344713533650728\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 2.310372430361964\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 3, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.2976153530046697\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 2.34181426883987\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.4898446560389034\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.5276104863639972\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.3193643886515654\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9758929750246501\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.9738755210104013\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.6906452356345918\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.1230000842301626\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 0.9749775237456505\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.5185360921934878\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.6177741477229912\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.796657939541949\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.9752289077099217\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.967236261141752\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9688489874213949\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.9854634500636705\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.0430421891577497\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.5999184857205526\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.6406033659198516\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.968691851276344\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.9331421211444524\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.6906564818930783\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.1503857852849693\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 0.7006286363672567\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.4796179392158888\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.5221498616559589\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.7966592945848403\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.849125375731467\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.960373192900634\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9479247714213184\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.977823862300173\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.9661342868634175\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.9376033243071364\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.5151488878942534\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9158817014567309\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.7070929480650237\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.6781760545616717\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 1.175092026317716\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 100}\n",
      "AdaBoostRegressor RMSE: 0.7204826257325365\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.4776421812973057\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.4226198389941148\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.795375233877535\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.5512772565025876\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.9085987130774285\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9222910278975223\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.9235172363800346\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.300525053673476\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.5344354695577207\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.064408409688842\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9690305169794569\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.8155095982034207\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.6889693349020967\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.1240530624316207\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 100}\n",
      "AdaBoostRegressor RMSE: 0.9031097399193627\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.4766872667703517\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.3870724816544579\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.7966643337175412\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.9601775992939092\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.9610023069492113\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.0044028557915852\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.977995600949481\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.180325579315672\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.6055482027643935\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.184623504821488\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9534431130473737\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.3800255432418633\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.6781760545616717\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.0948856311310067\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 0.7938782445710074\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.470795495589456\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.30351279628345984\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.795997857209833\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.9102186112504083\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.9453286533411684\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9402193691526992\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.9616071892828582\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.9691597211024552\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.7251182794476174\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.3262497713936254\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.9747918513896645\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.6408662092524993\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.6755276220666968\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.2215592894953484\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 0.7338804225633828\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.5069696775382353\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.4585582111633118\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.7967716093889259\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.9513449977314503\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.9663297152762822\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 0.9707403542366416\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.983943727149289\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.008146625001619\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.744223469252972\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.8556704506279744\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.995063878293594\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.0088170406117116\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.675527622066697\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 1.1430510848198274\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 20}\n",
      "AdaBoostRegressor RMSE: 0.9616547569711981\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 1.5145043358452432\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 0.4899804151760726\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.7966384086173508\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.9946979082628218\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.9864661468864906\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.1, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 2, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.0072857484503408\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 2.0051986929515793\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.0862043781899717\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.6562267464254754\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.2565763181570297\n",
      "Best models information saved to best_models_info.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "     'OF9', 'OF10', 'OF11', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24', 'F13',\n",
    "    'F41', 'F50', 'F51', 'F52'\n",
    "]\n",
    "\n",
    "results_columns = ['NR_Benefit']\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5, 10],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),\n",
    "    TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"NR_Benefit\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3abe42-6b55-4eba-91ee-f60baf5340f7",
   "metadata": {},
   "source": [
    "# PR Benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd4b6a2-417a-4646-82f3-aaad183c4d5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5983850152198624\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.4611910788968083\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071632\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 0.754467035015301\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.1, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.4530710069310848\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.8688351840123579\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'tanh', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 0.752656744223242\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.3652259639209197\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 4.054278817939986\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.6025545932935517\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.0001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.100950749289037\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2024125143903484\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': None}\n",
      "RANSACRegressor RMSE: 2.2004157733935834\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 2.5604456585274322\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.9423269933540463\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.8498215085333616\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.160414647771177\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071634\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 0.6213911401731721\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 20}\n",
      "AdaBoostRegressor RMSE: 1.3577232710743434\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.838905016730566\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.1387071868718652\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.4051050849269993\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 3.2041253130276357\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.8474386083583096\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.1345738216295396\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.0732480483808085\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.9822228092047178\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.6386602098094616\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.7639010179102226\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5932409873961457\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.7348835346664188\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071628\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'poisson', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 0.5605438744865214\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 100}\n",
      "AdaBoostRegressor RMSE: 1.4274374032052843\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.8419557544731626\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'tanh', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 0.8616650914464165\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.3653043870815784\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.0569143629768436\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.5974333622199741\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.0001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.1032026189616695\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2016228499513917\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.1058927454747027\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 2.6417569440710618\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4805591890680098\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5973250775957248\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.532533026133687\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071628\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 0.588102231631275\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 100}\n",
      "AdaBoostRegressor RMSE: 1.4185429368892786\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.867603757120912\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.1017998264500564\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.3652029030982276\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 3.186983598634739\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.601655952997773\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.0807648601411017\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2016228499513917\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.9532333518842584\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 2.5432025314728293\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.6013923530657077\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5387870896853686\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.9712485718701409\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071628\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 0.6584978347162385\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.2409122237437924\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 0.8119811970025625\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'tanh', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 0.8384981780623456\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.3642562557561604\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.077325706631558\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.5434086091274304\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.062830457806778\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2181723906689501\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 2}\n",
      "RANSACRegressor RMSE: 8969603301309.24\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.0278162528104544\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4837643843534758\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.594966654951807\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.920277908336079\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071634\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 0.6738993908447707\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.001, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.6954596496373993\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.7142184223746051\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.1389526565149457\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.3652259438987304\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 3.0445594966727993\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.5993229149727044\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.0831700993652804\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2016228499513917\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.9476262132352857\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.181029294751818\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.646494211368542\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5784607639760582\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.9346681101816176\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071628\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 100}\n",
      "RandomForestRegressor RMSE: 0.7082215070865904\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.4508310397173036\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 0.8298649703702519\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.0185766206966091\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.3648204837844\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.4573669954150692\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.5829649385768327\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.0864197425190896\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2073231094845542\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 10}\n",
      "RANSACRegressor RMSE: 887015310162.2897\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.480082613895088\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.9719799555044923\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5945442602517494\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.9258764547726364\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071628\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 0.5611967636275729\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.01, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.5191583351163795\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 2, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.845108235141766\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'tanh', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.194039762263836\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 1.3652305679137344\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 2.194814830147176\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.5989528858223252\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.001, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.086221198097785\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2016228499513917\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 2.5385171508541426\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.1778034190449462\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.5369005858088968\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.5995158200087412\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.1358144969265762\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 1.5425507592071634\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 50}\n",
      "RandomForestRegressor RMSE: 0.5004739372501498\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.01, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.2551377359945008\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "KNeighborsRegressor RMSE: 0.8389886674933091\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'logistic', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.1512162019929568\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 1.365226717031416\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.2764996999926175\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.6040590376534767\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'rbf'}\n",
      "KernelRidge RMSE: 2.0796716122032857\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': True}\n",
      "LinearRegression RMSE: 1.2031079047243776\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.0522888816453377\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 2.615288287667422\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4539205866477782\n",
      "Best models information saved to best_models_info.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "    \n",
    "    'OF18', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24',\n",
    "    'F41',  'F48', 'F50',  'F52'\n",
    "]\n",
    "\n",
    "results_columns = ['PR_Benefit']\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5, 10],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),\n",
    "    TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"PR_Benefit\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14e409-0cb4-4341-8c30-9918628afcea",
   "metadata": {},
   "source": [
    "# SR Benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0969a3b2-2592-4493-a245-630e18d716c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'svd'}\n",
      "Ridge RMSE: 1.1287751101652872\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 1, 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 2.7580886778278004\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.1338271053215763\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.6953156498751998\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.0830853189362497\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 7.657545710877855\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.265287467452089\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.499014179774042\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.1343816857525633\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.1344219053012439\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.134429786762947\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': None}\n",
      "RANSACRegressor RMSE: 1.617503392197956\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.5885345491004289\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.8581672155871881\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sparse_cg'}\n",
      "Ridge RMSE: 1.4723363104253813\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 3.5993440143077917\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.6969627524884963\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.7299544935303692\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.1906104952622294\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 1.4735876479681078\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.2960195955392617\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.9883662785134564\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.4733940956789713\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'linear'}\n",
      "KernelRidge RMSE: 3.444234918492636\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': False, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 3.444235530872611\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.3597059035924308\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 1.0585237643863359\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4703402620820752\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sparse_cg'}\n",
      "Ridge RMSE: 1.116443326477427\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 0.9507184250920583\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 0.9522773705576493\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.5695846887595948\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 0.9681165307662384\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 1.1233975873232074\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.264720114031431\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.9671356407922543\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.1264911334944088\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'linear'}\n",
      "KernelRidge RMSE: 3.2147503639831987\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.1265364873108037\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.2449468692726686\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.6080291757360768\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4090198784300626\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sparse_cg'}\n",
      "Ridge RMSE: 1.1147700814830763\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.1299952380852045\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.2186945646998306\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.1598858670663685\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.0707001011799089\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 6.249211309920087\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.264719878957338\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.984466977526284\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.125407954599968\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'linear'}\n",
      "KernelRidge RMSE: 3.2132285117993376\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': False, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 3.213229103647456\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.6931953448440697\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.6202133557103255\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.5793497731856858\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'svd'}\n",
      "Ridge RMSE: 1.0581495690284433\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.6718572934086837\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.7234343895948272\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.01, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.15605322431806\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.082108993938182\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 3.499136649370845\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.0189803852697734\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 0.8869170115291244\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.0324939772681057\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 0.0001, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'sigmoid'}\n",
      "KernelRidge RMSE: 13.207938284280281\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': False, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 3.1473197848740417\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.649230481539442\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.6704733623551902\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.602006642884619\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'lsqr'}\n",
      "Ridge RMSE: 1.1295996888248157\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.6461768875907883\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.0756441914557056\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 50}\n",
      "AdaBoostRegressor RMSE: 1.1913103189484222\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.0463115519813035\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 1.272182732745365\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.253854402709294\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.9726352067707463\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.1348291462554911\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.1348670358090858\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.134874384788631\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.3334666463450957\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.587980081473846\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.4913290513582919\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'svd'}\n",
      "Ridge RMSE: 1.1000789660598869\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 1, 'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 2.6558153801296758\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.998585845279702\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.5836047313944492\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.1061365038900468\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 4.945595254435055\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 2.2637803428833108\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.9734090345765962\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.1055431949492887\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.1055824583164136\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.1055901807778041\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.183078691893767\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.6329326330313249\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.6408875564044197\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sparse_cg'}\n",
      "Ridge RMSE: 1.1182279126713577\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.6032701960145617\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': False}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.5594856752880328\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 20}\n",
      "AdaBoostRegressor RMSE: 1.518863040569496\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.103763607153357\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 1.0007024986565631\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 2.2665042521461496\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 0.9693957053803893\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.129442878482375\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'sigmoid'}\n",
      "KernelRidge RMSE: 4.132980265222758\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': False, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 3.229590436436619\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': None}\n",
      "RANSACRegressor RMSE: 1036839356810.5742\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.9037326855048533\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.7446507102728493\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 0.1, 'ridge__solver': 'sparse_cg'}\n",
      "Ridge RMSE: 1.1182279126713577\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 3, 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 1.6029381430598595\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 3.384579436999508\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.790584159702221\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.0001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 2.0538851389115025\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'brute', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'cosine', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.103763607153357\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 3.0875133243683637\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.75, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 2.2626836648891113\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'adaptive', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 0.9776946220224598\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-05, 'bayesianridge__alpha_2': 1e-07, 'bayesianridge__lambda_1': 1e-07, 'bayesianridge__lambda_2': 1e-05}\n",
      "BayesianRidge RMSE: 1.129442878482375\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1e-05, 'kernelridge__coef0': 0.5, 'kernelridge__degree': 1, 'kernelridge__kernel': 'sigmoid'}\n",
      "KernelRidge RMSE: 4.132980265222758\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': False, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 3.229590436436619\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.246101795718531\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 0.9155703819833385\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 0.6513328153298242\n",
      "Best models information saved to best_models_info.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = ['OF18', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24','F24', 'F28','F41', 'F50', 'F52', 'F55', 'S4', ]\n",
    "\n",
    "results_columns = ['SR_Benefit']\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5, 10],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "    BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),\n",
    "    TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"SR_Benefit\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bc889-6d9e-4f1e-b8e0-4c1b9ba3f30e",
   "metadata": {},
   "source": [
    "# SFST Benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bc7686-4685-40ee-97dc-dff3182ea232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.3950050782333883\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 1, 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.8617692166515776\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.6899000800256778\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.7613302768451835\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 1.7400023659107484\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 7.825975911320573\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 6.8276962948731965\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.5016251671696723\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.5024586862698832\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_bfill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.047804415322723\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'cholesky'}\n",
      "Ridge RMSE: 1.3934750579470139\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 1, 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 2.304956502017007\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.2461959505720688\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.969954235911166\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 4.1124437790655195\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 7.82503438831255\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': 'elasticnet', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.691349228364125\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 2}\n",
      "RANSACRegressor RMSE: 2.8351731486958833\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.4530824934676017\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_custom_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.8486653588767472\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.398134773289042\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.7133056324385043\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.1127957125891093\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 2.13438871399481\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 1.517006037719683\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 10.043194616643502\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.4582834441307497\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 10, 'ransacregressor__min_samples': 50}\n",
      "RANSACRegressor RMSE: 1.487334200979342\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 10}\n",
      "TheilSenRegressor RMSE: 2.186889060846393\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_ffill_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.9635211530837737\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.3944610261314925\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.4744590210520958\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.644460976672346\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.001, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.9797471968713443\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 4.428136226707196\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 10.05598133171932\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.4032046189177196\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 1, 'ransacregressor__min_samples': 2}\n",
      "RANSACRegressor RMSE: 1.5800245731031557\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 2.705536791613148\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_interpolated.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.0467587563928933\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'cholesky'}\n",
      "Ridge RMSE: 1.3934750579470139\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'squared_error', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 2.2532788371298262\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 'log2', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.1562925881804564\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'exponential', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.8925614024706365\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 5.640787814561951\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 10.047667267026497\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.5058192005716162\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 2}\n",
      "RANSACRegressor RMSE: 1.303225786800947\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 1.7970908249994157\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_iterative_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.2336845105710648\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.395144230337694\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 4, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.3292752764502958\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.1241771544137587\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 10, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.9910660457287153\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'relu', 'mlpregressor__hidden_layer_sizes': (100, 100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'lbfgs'}\n",
      "MLPRegressor RMSE: 2.6868473950224434\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': True, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': False, 'elasticnet__selection': 'cyclic', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 10.043352405035103\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'huber', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.5053954825938511\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 100, 'ransacregressor__min_samples': 10}\n",
      "RANSACRegressor RMSE: 1.9791684302461714\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 100, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.470352190318444\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_knn_imputed_custom.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.3374726566186594\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'saga'}\n",
      "Ridge RMSE: 1.382456118132558\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'absolute_error', 'decisiontreeregressor__max_features': 'log2', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 2.1398959559709794\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.7777081423017655\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'linear', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.8012048169442976\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (100, 100, 100), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 2.7620980099025965\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': True, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 7.825802522084094\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'optimal', 'sgdregressor__loss': 'epsilon_insensitive', 'sgdregressor__penalty': 'l1', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 3.1908801126212154\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'absolute_error', 'ransacregressor__max_trials': 150, 'ransacregressor__min_samples': 1}\n",
      "RANSACRegressor RMSE: 2.0494709737534595\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 1000, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 3.155703213057038\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mean_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.6595057959069115\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'cholesky'}\n",
      "Ridge RMSE: 1.3934750579470139\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 'sqrt', 'decisiontreeregressor__min_samples_split': 5, 'decisiontreeregressor__splitter': 'random'}\n",
      "DecisionTreeRegressor RMSE: 1.4516433197282452\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'friedman_mse', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 2.1167757726504464\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 0.1, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.9911438946083484\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'constant', 'mlpregressor__solver': 'adam'}\n",
      "MLPRegressor RMSE: 5.176287876031864\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': True}\n",
      "ElasticNet RMSE: 10.043159604163598\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': 'l2', 'sgdregressor__warm_start': False}\n",
      "SGDRegressor RMSE: 1.4127733613795987\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 10}\n",
      "RANSACRegressor RMSE: 1.5909746494448282\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': 25}\n",
      "TheilSenRegressor RMSE: 1.4549002736394574\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_median_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.6054065701042286\n",
      "Processing Ridge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for Ridge: {'ridge__alpha': 1.0, 'ridge__solver': 'sag'}\n",
      "Ridge RMSE: 1.4066997734955788\n",
      "Processing DecisionTreeRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for DecisionTreeRegressor: {'decisiontreeregressor__criterion': 'friedman_mse', 'decisiontreeregressor__max_features': 2, 'decisiontreeregressor__min_samples_split': 3, 'decisiontreeregressor__splitter': 'best'}\n",
      "DecisionTreeRegressor RMSE: 2.0829475595209512\n",
      "Processing GradientBoostingRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for GradientBoostingRegressor: {'gradientboostingregressor__learning_rate': 0.001, 'gradientboostingregressor__loss': 'huber', 'gradientboostingregressor__n_estimators': 25, 'gradientboostingregressor__warm_start': True}\n",
      "GradientBoostingRegressor RMSE: 2.1776267574666877\n",
      "Processing RandomForestRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RandomForestRegressor: {'randomforestregressor__criterion': 'absolute_error', 'randomforestregressor__max_features': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 1}\n",
      "RandomForestRegressor RMSE: 1.8890724670362136\n",
      "Processing AdaBoostRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for AdaBoostRegressor: {'adaboostregressor__learning_rate': 1.0, 'adaboostregressor__loss': 'square', 'adaboostregressor__n_estimators': 1}\n",
      "AdaBoostRegressor RMSE: 1.815467425095213\n",
      "Processing KNeighborsRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KNeighborsRegressor: {'kneighborsregressor__algorithm': 'ball_tree', 'kneighborsregressor__leaf_size': 5, 'kneighborsregressor__metric': 'euclidean', 'kneighborsregressor__n_neighbors': 10, 'kneighborsregressor__weights': 'uniform'}\n",
      "KNeighborsRegressor RMSE: 1.7055107226980708\n",
      "Processing MLPRegressor(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for MLPRegressor: {'mlpregressor__activation': 'identity', 'mlpregressor__hidden_layer_sizes': (50, 50, 50), 'mlpregressor__learning_rate': 'invscaling', 'mlpregressor__solver': 'sgd'}\n",
      "MLPRegressor RMSE: 1.4247080759844977\n",
      "Processing ElasticNet() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for ElasticNet: {'elasticnet__copy_X': False, 'elasticnet__fit_intercept': False, 'elasticnet__l1_ratio': 0.25, 'elasticnet__positive': False, 'elasticnet__precompute': True, 'elasticnet__selection': 'random', 'elasticnet__warm_start': False}\n",
      "ElasticNet RMSE: 10.041905178424065\n",
      "Processing SGDRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for SGDRegressor: {'sgdregressor__learning_rate': 'constant', 'sgdregressor__loss': 'squared_error', 'sgdregressor__penalty': None, 'sgdregressor__warm_start': True}\n",
      "SGDRegressor RMSE: 1.425601600353176\n",
      "Processing BayesianRidge(max_iter=1000) for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for BayesianRidge: {'bayesianridge__alpha_1': 1e-07, 'bayesianridge__alpha_2': 1e-05, 'bayesianridge__lambda_1': 1e-05, 'bayesianridge__lambda_2': 1e-07}\n",
      "BayesianRidge RMSE: 1.4228771725717677\n",
      "Processing KernelRidge() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for KernelRidge: {'kernelridge__alpha': 1.0, 'kernelridge__coef0': 1.0, 'kernelridge__degree': 1, 'kernelridge__kernel': 'poly'}\n",
      "KernelRidge RMSE: 1.4459037072042868\n",
      "Processing LinearRegression() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for LinearRegression: {'linearregression__copy_X': True, 'linearregression__fit_intercept': True, 'linearregression__positive': False}\n",
      "LinearRegression RMSE: 1.422892247317659\n",
      "Processing RANSACRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for RANSACRegressor: {'ransacregressor__loss': 'squared_error', 'ransacregressor__max_trials': 50, 'ransacregressor__min_samples': 2}\n",
      "RANSACRegressor RMSE: 1.6983374234680866\n",
      "Processing TheilSenRegressor() for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "Best hyperparameters for TheilSenRegressor: {'theilsenregressor__max_subpopulation': 10, 'theilsenregressor__n_subsamples': None}\n",
      "TheilSenRegressor RMSE: 4.201883031355524\n",
      "Processing TensorFlow for ../../Data_ML/out_csvs_regression\\output_mode_imputed.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 2.106899585761205\n",
      "Best models information saved to best_models_info.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = ['OF18', 'OF22','OF25',  'OF27', 'OF28',  'F50']\n",
    "\n",
    "results_columns = ['SFST_Benefit']\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'ridge__alpha': [0.1, 0.5, 1.0],\n",
    "        'ridge__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'decisiontreeregressor__splitter': ['best', 'random'],\n",
    "        'decisiontreeregressor__min_samples_split': [1, 2, 3, 4, 5],\n",
    "        'decisiontreeregressor__max_features': [0, 1, 2, 3, 'sqrt', 'log2']\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__n_estimators': [1, 50, 100],\n",
    "        'randomforestregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        'randomforestregressor__min_samples_split': [2, 5],\n",
    "        'randomforestregressor__max_features': [1, 3, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'gradientboostingregressor__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'gradientboostingregressor__learning_rate': [0.001, 0.01],\n",
    "        'gradientboostingregressor__n_estimators': [25, 50, 100],\n",
    "        'gradientboostingregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'AdaBoostRegressor': {\n",
    "        'adaboostregressor__n_estimators': [1, 20, 50, 100],\n",
    "        'adaboostregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'adaboostregressor__loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [2, 5, 10, 25],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "        'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsregressor__leaf_size': [5, 30, 50],\n",
    "        'kneighborsregressor__metric': ['cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'mlpregressor__hidden_layer_sizes': [(50, 50, 50), (100, 100, 100), (100, 100, 100, 100)],\n",
    "        'mlpregressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'elasticnet__fit_intercept': [True, False],\n",
    "        'elasticnet__precompute': [True, False],\n",
    "        'elasticnet__copy_X': [True, False],\n",
    "        'elasticnet__warm_start': [True, False],\n",
    "        'elasticnet__positive': [True, False],\n",
    "        'elasticnet__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'SGDRegressor': {\n",
    "        'sgdregressor__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'sgdregressor__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'sgdregressor__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'sgdregressor__warm_start': [True, False],\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'svr__degree': [1, 3, 5, 10],\n",
    "        'svr__gamma': ['scale', 'auto', 1.0, 5.0],\n",
    "        'svr__shrinking': [True, False]\n",
    "    },\n",
    "    'BayesianRidge': {\n",
    "        'bayesianridge__alpha_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__alpha_2': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_1': [1e-7, 1e-6, 1e-5],\n",
    "        'bayesianridge__lambda_2': [1e-7, 1e-6, 1e-5],\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'kernelridge__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernelridge__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'kernelridge__degree': [1, 2, 3, 5, 10],\n",
    "        'kernelridge__coef0': [0.0, 0.5, 1.0]\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__copy_X': [True, False],\n",
    "        'linearregression__positive': [True, False]\n",
    "    },\n",
    "    'RANSACRegressor': {\n",
    "        'ransacregressor__min_samples': [None, 1, 2, 5, 10, 50],\n",
    "        'ransacregressor__max_trials': [1, 10, 50, 100, 150],\n",
    "        'ransacregressor__loss': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'TheilSenRegressor': {\n",
    "        'theilsenregressor__max_subpopulation': [1, 10, 100, 1000],\n",
    "        'theilsenregressor__n_subsamples': [None, 1, 5, 10, 25],\n",
    "    }\n",
    "}\n",
    "\n",
    "models = [\n",
    "    Ridge(), DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor(), AdaBoostRegressor(),\n",
    "    KNeighborsRegressor(), MLPRegressor(max_iter=1000), ElasticNet(max_iter=1000), SGDRegressor(max_iter=1000),\n",
    "   BayesianRidge(max_iter=1000), KernelRidge(), LinearRegression(), RANSACRegressor(),\n",
    "    TheilSenRegressor()\n",
    "]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory where you want to save your models\n",
    "model_directory = \"SFST_Benefit\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    best_model_info = {\n",
    "        'csv_file': os.path.basename(file_path),\n",
    "        'model_name': None,\n",
    "        'hyperparameters': None,\n",
    "        'rmse': float('inf')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model in models + ['TensorFlow']:  # Add TensorFlow model to the loop\n",
    "        print(f\"Processing {model} for {file_path}\")\n",
    "        if model == 'TensorFlow':\n",
    "            # Define the TensorFlow model\n",
    "            model_tf = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            # Compile the TensorFlow model\n",
    "            model_tf.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            # Standardize the data for TensorFlow model\n",
    "            scaler_tf = StandardScaler()\n",
    "            X_train_scaled_tf = scaler_tf.fit_transform(X_train)\n",
    "            X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "            # Train the TensorFlow model\n",
    "            model_tf.fit(X_train_scaled_tf, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate the TensorFlow model\n",
    "            y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "            rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "            print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "            if rmse_tf < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': 'TensorFlow',\n",
    "                    'hyperparameters': None,\n",
    "                    'rmse': rmse_tf\n",
    "                })\n",
    "\n",
    "            # Save the TensorFlow model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_TensorFlow_model.h5\")\n",
    "            model_tf.save(model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred_tf.flatten(), 'Model': 'TensorFlow'}))\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "            pipeline = make_pipeline(StandardScaler(), model)\n",
    "            # Perform grid search for hyperparameters\n",
    "            if model_name in param_grid:\n",
    "                grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_estimator = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "            else:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_estimator = pipeline\n",
    "                best_params = None\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"{model_name} RMSE: {rmse}\")\n",
    "\n",
    "            if rmse < best_model_info['rmse']:\n",
    "                best_model_info.update({\n",
    "                    'model_name': model_name,\n",
    "                    'hyperparameters': best_params,\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = os.path.join(model_directory, f\"{os.path.basename(file_path)}_{model_name}_model.pkl\")\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the predictions and actual values\n",
    "            results.append(pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': y_pred.flatten(), 'Model': model_name}))\n",
    "\n",
    "    # Save the predictions and actual values to a CSV file\n",
    "    results_df = pd.concat(results, axis=0)\n",
    "    results_filename = f\"output_{os.path.basename(file_path)}_{results_columns[0]}.csv\"\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "    return best_model_info\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = glob.glob('../../../Data_ML/4_out_csvs_regression/*.csv')\n",
    "\n",
    "# Initialize a list to store the best model information for each CSV file\n",
    "best_models_info = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    best_model_info = process_csv(csv_file)\n",
    "    best_models_info.append(best_model_info)\n",
    "\n",
    "# Save the best model information for each CSV file to a CSV file\n",
    "best_models_df = pd.DataFrame(best_models_info)\n",
    "best_models_df.to_csv(\"best_models\"+results_columns[0]+\"_info.csv\", index=False)\n",
    "\n",
    "print(\"Best models information saved to best_models_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a049f-5075-4a55-9ef8-e988af4cb6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97faf8a-29e9-4d5c-a30e-1f788cdc5bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b7730-7cfc-4078-9b64-04c07a5861d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
