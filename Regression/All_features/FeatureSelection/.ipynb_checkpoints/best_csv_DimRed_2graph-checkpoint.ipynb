{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02626ce2-63f2-4ee6-9dbb-feaf85f28302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator AdaBoostRegressor from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA dimensionality reduction\n",
      "Applying UMAP dimensionality reduction\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, FastICA, KernelPCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet, SGDRegressor, BayesianRidge, LinearRegression, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import umap\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Define the data columns and results columns\n",
    "data_columns = [\n",
    "    'OF2', 'OF3', 'OF4', 'OF5', 'OF6', 'OF7', 'OF8', 'OF9', 'OF10', 'OF11', 'OF13', 'OF14', 'OF15', 'OF16', 'OF17',\n",
    "    'OF18', 'OF19', 'OF20', 'OF21', 'OF22', 'OF23', 'OF24', 'OF25', 'OF26', 'OF27', 'OF28', 'OF30', 'OF31',\n",
    "    'OF33', 'OF34', 'OF37', 'OF38', 'F1', 'F2', 'F3_a', 'F3_b', 'F3_c', 'F3_d', 'F3_e', 'F3_f', 'F3_g', 'F4', 'F5', 'F6',\n",
    "    'F7', 'F8', 'F9', 'F10', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23',\n",
    "    'F24', 'F25', 'F28', 'F29', 'F30', 'F31', 'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40',\n",
    "    'F41', 'F43', 'F44', 'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F56', 'F57',\n",
    "    'F58', 'F59', 'F62', 'F63', 'F64', 'F65', 'F67', 'F68', 'S1', 'S2', 'S4', 'S5'\n",
    "]\n",
    "\n",
    "results_columns = ['WS']\n",
    "\n",
    "# Implement dimensionality reduction techniques\n",
    "dimensionality_reduction_techniques = {\n",
    "    \"PCA\": PCA(n_components=10),\n",
    "    \"UMAP\": umap.UMAP(n_components=10),\n",
    "    \"Isomap\": Isomap(n_components=10),\n",
    "    \"LLE\": LocallyLinearEmbedding(n_components=10),\n",
    "    \"Autoencoders\": TruncatedSVD(n_components=10),  # Assuming TruncatedSVD as a simple autoencoder\n",
    "    \"ICA\": FastICA(n_components=10),\n",
    "    \"Kernel PCA\": KernelPCA(n_components=10),\n",
    "    \"Random Projection\": GaussianRandomProjection(n_components=10)  # Assuming GaussianRandomProjection\n",
    "}\n",
    "\n",
    "# Define a mapping from model names to model classes\n",
    "model_mapping = {\n",
    "    'Ridge': Ridge,\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor,\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor,\n",
    "    'RandomForestRegressor': RandomForestRegressor,\n",
    "    'AdaBoostRegressor': AdaBoostRegressor,\n",
    "    'KNeighborsRegressor': KNeighborsRegressor,\n",
    "    'MLPRegressor': MLPRegressor,\n",
    "    'ElasticNet': ElasticNet,\n",
    "    'SGDRegressor': SGDRegressor,\n",
    "    'SVR': SVR,\n",
    "    'BayesianRidge': BayesianRidge,\n",
    "    'KernelRidge': KernelRidge,\n",
    "    'LinearRegression': LinearRegression,\n",
    "    'RANSACRegressor': RANSACRegressor,\n",
    "    'TheilSenRegressor': TheilSenRegressor\n",
    "}\n",
    "\n",
    "# Function to load, evaluate and retrain the model with dimensionality reduction\n",
    "def load_evaluate_and_retrain_model(csv_file, model_name, model_path, hyperparameters):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    X = data[data_columns]\n",
    "    y = data[results_columns[0]]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Load the original model and calculate RMSE\n",
    "    if model_name == 'TensorFlow':\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model = joblib.load(model_path)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    rmse_original = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    reduction_results = {'Original': rmse_original}\n",
    "\n",
    "    # Iterate over a range of component values for each dimensionality reduction technique\n",
    "    for name, reducer in dimensionality_reduction_techniques.items():\n",
    "        print(f\"Applying {name} dimensionality reduction\")\n",
    "        rmse_values = []\n",
    "    \n",
    "        for n_components in range(2, 26):  # Range from 2 to 25 components\n",
    "            # Create a pipeline that includes scaling and dimensionality reduction\n",
    "            if name == \"t-SNE\":\n",
    "                # t-SNE requires special handling as it does not support transform\n",
    "                X_concatenated = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
    "                if n_components<=4:\n",
    "                    reducer=TSNE(n_components=4)\n",
    "                else:\n",
    "                    reducer=TSNE(n_components=n_components)\n",
    "                X_reduced = reducer.fit_transform(X_concatenated)\n",
    "                X_train_reduced = X_reduced[:len(X_train_scaled)]\n",
    "                X_test_reduced = X_reduced[len(X_train_scaled):]\n",
    "            else:\n",
    "                # Set the number of components for the reducer\n",
    "                reducer.set_params(n_components=n_components)\n",
    "                pipeline = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('reducer', reducer)\n",
    "                ])\n",
    "                X_train_reduced = pipeline.fit_transform(X_train)\n",
    "                X_test_reduced = pipeline.transform(X_test)\n",
    "    \n",
    "            # Retrain the model with the reduced data\n",
    "            if model_name == 'TensorFlow':\n",
    "                model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.InputLayer(input_shape=(X_train_reduced.shape[1],)),\n",
    "                    tf.keras.layers.Dense(hyperparameters['units'], activation=hyperparameters['activation']),\n",
    "                    tf.keras.layers.Dense(1)\n",
    "                ])\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "                              loss='mse')\n",
    "                model.fit(X_train_reduced, y_train, epochs=hyperparameters['epochs'], verbose=0)\n",
    "                y_pred = model.predict(X_test_reduced)\n",
    "            else:\n",
    "                # Dynamically select the model class based on the model name\n",
    "                model_class = model_mapping.get(model_name)\n",
    "                if not model_class:\n",
    "                    print(f\"Unknown model name: {model_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Filter hyperparameters for the selected model\n",
    "                model_hyperparameters = {k.split('__', 1)[1]: v for k, v in hyperparameters.items() if k.startswith(model_name.lower())}\n",
    "                model = model_class(**model_hyperparameters)\n",
    "                model.fit(X_train_reduced, y_train)\n",
    "                y_pred = model.predict(X_test_reduced)\n",
    "    \n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            rmse_values.append(rmse)\n",
    "    \n",
    "        reduction_results[name] = rmse_values\n",
    "\n",
    "    return reduction_results\n",
    "model_directory = \"WS\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the best models information\n",
    "best_models_df = pd.read_csv(\"best_modelsWS_info.csv\")\n",
    "\n",
    "# Find the row corresponding to the model with the lowest RMSE\n",
    "best_model_row = best_models_df.loc[best_models_df['rmse'].idxmin()]\n",
    "\n",
    "# Extract information about the best model\n",
    "csv_file = os.path.join('./model_all_data', best_model_row['csv_file'])\n",
    "model_name = best_model_row['model_name']\n",
    "model_path = os.path.join(model_directory, f\"{best_model_row['csv_file']}_{model_name}_model.pkl\" if model_name != 'TensorFlow' else f\"{best_model_row['csv_file']}_TensorFlow_model.h5\")\n",
    "hyperparameters = ast.literal_eval(best_model_row['hyperparameters'])\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Evaluate the best model with dimensionality reduction\n",
    "reduction_results = load_evaluate_and_retrain_model(csv_file, model_name, model_path, hyperparameters)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Plot RMSE values for each reduction method\n",
    "for name, rmse_values in reduction_results.items():\n",
    "    if name != 'Original':  # Skip 'Original' since it doesn't have varying components\n",
    "        plt.plot(range(2, 26), rmse_values, label=name,marker='o',)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Number of Components for Dimensionality Reduction Techniques '+{model_directory})\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"dimensionality_reduction_rmse_plot_\"+model_directory+\"_best.png\")\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886002c-c0d6-489a-8950-55d123b6704c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e850a-4d8e-4387-9f10-b0996d127e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed92e9c-b8bd-4c83-84af-16f7369648b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c953a-5739-413b-8598-4d7ae789ce72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623a15d-6b53-447e-8450-ef86e6031d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0cc80-0331-43a5-89a0-f6d22b2e229f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ba154-753e-45a0-8f0b-533d6a51c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c87869-d74c-42fe-943e-c056eb7381ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18672b92-1b70-4586-8cef-dd2a114bb894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdad3c6-33b5-4b0a-a999-ed5ae2505aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea98bd9-004f-40cf-8aaa-19c1e056cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b8f96-31b5-41e4-948d-7f572afe5392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5773af9-22a7-4d6a-a7be-e2bff4b7c4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
